\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{wasysym}
\usepackage{ulem}
\usepackage{xspace}
\usepackage{booktabs}
\usepackage{physics}

\ifPDFTeX % ensure generation of machine readable output
\input{glyphtounicode}
\pdfgentounicode=1
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\fi

\usepackage{csquotes}

\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\Nul}{Nul}
\DeclareMathOperator{\Row}{Row}
\DeclareMathOperator{\proj}{proj}

\setlength{\arraycolsep}{12pt}

\newcommand{\defn}{\textbf{Def.}\xspace}
\newcommand{\thm}{\textbf{Thm.}\xspace}
\newcommand{\ex}{\textbf{ex.}\xspace}
\newcommand{\Ex}{\textbf{Ex.}\xspace}
\newcommand{\ie}{\textbf{i.e.}\xspace}
\newcommand{\lemma}{\textit{Lemma}\xspace}
\newcommand{\bproof}{\textit{Proof ($\impliedby$).}\xspace}
\newcommand{\fproof}{\textit{Proof ($\implies$).}\xspace}
\newcommand{\bigEps}{\mathcal{E}}
\newcommand{\soln}{\textit{Soln.}\xspace}

\renewcommand{\arraystretch}{1.25} % Adjust row spacing

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=blue,      
    urlcolor=blue,
}

\newcommand{\ulhref}[2]{\href{#1}{\color{blue}\uline{#2}}}

\begin{document}

\title{MACM 316 Lecture 33}
\author{Alexander Ng}
\date{Wednesday, April 2, 2025}

\maketitle

\section{Euler's Method}
This section starts with Euler's Method Error Analysis. The analysis is
straightforward, and interesting because it can be extended to the higher order
methods that will be discussed in later sections. To derive the proof of
convergence, we need the following

\lemma: If $s$ and $t$ are positive real numbers, $\{a_i\}_{i=0}^k$ is a
sequence satisfying
\begin{align*}
  a_0 &\geq -\frac{t}{s} \\
  a_{i+1} &\leq (1+s) a_i + t \quad i = 0, 1, \ldots, k
\end{align*}
then $\displaystyle a_{i+1}\leq e^{(i+1)s}\left(a_0 + \frac{t}{s}\right) - \frac{t}{s}$

The proof of the lemme is not important, but it is included in section 23.5 of
the Chapter 5 lecture notes.

\subsection{Theorem 1 (23.6)}
Suppose $f$ is continuous and satisifes a Lipschitz condition with constant $L$
on
\[
D = \{(t,y) : a \leq t \leq b, -\infty < y < \infty \}
.\]
and that a constant $M$ exists with the property that
\[
  \abs{y''(t)} \leq M
.\]
Let $y(t)$ denote the unique solution to the initial value problem
\[
  y' = f(t,y); \quad y(a) = y_0, a \leq t \leq b
.\]
and $w_0, w_1, \dots, w_N$ be the approximations generated by Euler's Method.

Then, for each $i=0, \dots, N$, 
\[
  \abs{y(t_i) - w_i} \leq \frac{hM}{2L}\left[e^{L(t_i-a)}-1\right]
.\]

\proof (23.7) (I didn't add it yet)

Note that the theorem \uline{requires} that  
\[
  \abs{y''(t)} \leq M
.\]
The second derivative $y''(t)$ may not be known, but if $\frac{\partial
f}{\partial t}$ and $\frac{\partial f}{\partial y}$ exist,
\begin{align*}
  y''(t) = \frac{d}{dt} y'(t) &= \frac{df}{dt}(t,y(t)) \\
                              &= \frac{\partial f}{\partial
  t}(t,y(t)) + \frac{\partial f}{\partial y}(t,y(t)) \cdot f(t,y(t))
\end{align*}

\subsubsection{Example (23.8)}
What value of $h$ is needed to ensure that $\abs{y(t_i) - w_i} \leq 0.1$ for the
initial value problem
\[
  \begin{cases}
    y' = \frac{2}{t} y + t^2 e^t & 1 \leq t \leq 2 \\
    y = 0 & t = 1
  .\end{cases}
.\]
You are given $y''(t) = (2+4t+t^2)e^t - 2e$

\soln (23.9) $y''(t)$ is increasing and positive on $[1,2]$, so
\begin{align*}
  \abs{y''(t)} &\leq \abs{y''(2)} \\
  &= 14e^2 - 2e \\
  &= 98.0102 \\
\end{align*}
\begin{align*}
  \text{since}\quad & \abs{\frac{\partial}{\partial y} \left(\frac{2}{t}y +
  t^2e^2\right)} \\
                &\quad\leq \abs{\frac{2}{t}} \\
                &\quad\leq 2 \\
\end{align*}
a Lipschitz Constant for $f(t,y) = \frac{2}{t}y+t^2e^t$ is $L = 2$.
\[
\therefore \abs{y(t_i) - w_i} \leq \frac{hM}{2L}\left[e^{L(t_i-1)}-1\right] \leq
0.1
.\]
we need to choose $h$ so that $\displaystyle \frac{98.0102h}{4}
\left[e^{2(2-1)}-1 \right] \leq 0.1$.
\[
\implies h \leq \frac{0.4}{98.0102(e^2-1)} = 0.00064
.\]

\section{The Difference Method}
We ned a way to compare the efficiency of different approximation methods. The
difference method compares how much the exact solution to the differential
equation fails to satisfy the difference equation being used for the approximation.

\defn The Difference Method
\begin{align*}
  w_0 &= \alpha \\
  w_{i+1} &= w_i + h \phi (t_i, w_i)
\end{align*}
has a local trunctation error 
\begin{align*}
  \tau_{i+1}(h) &= \frac{y(t_{i+1}) - (y(t_i) + h \phi (t_i, y(t_i)))}{h} \\
                &= \frac{y(t_{i+1}) - y(t_i)}{h} - \phi(t_i, y(t_i)) 
                & i = 0, 1, \dots, N-1
\end{align*}

\subsection{Example: Euler's Method (23.11)}
The difference method for Euler's Method has $\phi = f$.
\begin{align*}
  w_0 &= \alpha \\
  w_{i+1} &= w_i + h \phi(t_i, w_i) = w_i + h f(t_i, w_i)
\end{align*}
has local truncation error
\begin{align*}
  \tau_{i+1}(h) &= \frac{y(t_{i+1}) - y(t_i)}{h} - f(t_i, y(t_i)) \\
                &= \frac{y(t_i) + hy'(t_i) + \frac{h^2}{2}y''(\xi)}{den} & \text{we do a taylor expansion} \\
\end{align*}

Local truncation errors are called local because they measure hte accuracy of
the method at a specific step, assuming the method was exact at the previous
steps. We obviously want the local truncation error to be small. Often, methods
for solving ODE's are derived so that the local truncation errors are of the
form
\[
O(h^p)
.\]
for the largest possible $p$, while keeping the number of operations reasonable.

\subsection{How to obtain improved accuracy?}
\ie a larger $p$ in the $O(h^p)$ local truncation error.

Suppose we want to approximate the solution to the ivp 
\[
  \begin{cases}
    y' = f(t,y) & a \leq t \leq b\\
    y = \alpha & t = 0
  .\end{cases}
.\]
where $y(t) \in C^{(n+1)} [a,b]$

One approach is to expand the solution in terms of its $n^{th}$ Taylor
Polynomial about $t_i$.
\[
math
.\]

\section{The Taylor Method of Order $n$}
If we drop the remainder term, we obtain the \textbf{Taylor Method of Order $n$}.

\end{document}
