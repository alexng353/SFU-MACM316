\documentclass[12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{wasysym}
\usepackage{ulem}

\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\Nul}{Nul}
\DeclareMathOperator{\Row}{Row}
\DeclareMathOperator{\proj}{proj}

\begin{document}

\renewcommand{\arraystretch}{1.25} % Adjust row spacing
\setlength{\arraycolsep}{12pt}

\title{MACM 316 Lecture 11 - Chapter 6.2}
\author{Alexander Ng}
\date{Wednesday, January 29, 2025}
\maketitle

\section{More Special Matrices}

\subsection{Band Matrices}
Another important class of matrices that arise in a wide variety of 
applications are called band matrices. These matrices concentrate all their 
nonzero entries about the diagonal.

\subsubsection{Definition}
An $n \times n$ matrix is called a band matrix if there exist integers $p$ and
$q$ such that $1 < p, q < n$ having the property that $a_{ij} = 0$ whenever
$i + p \leq j$ or $j + q \leq i$.

The bandwidth of a band matrix is defined as $w = p+q-1$. We subtract 1 from 
our count because we do not want to double count the diagonal.

We will focus on the important case of tridiagonal matrices, which are band 
matrices with $p = q = 2$, i.e., the matrix is tridiagonal if the nonzero 
entries are on the main diagonal and the diagonals above and below the main 
diagonal.

Suppose $A$ can be factored into the triangular matrices $L$ and $U$. Suppose
that the matrices can be found in the form:

\[
L = \begin{bmatrix}
    l_{11} & 0 & \dots & 0 \\
    l_{21} & l_{22} & & \\
    & & \ddots & \\
    0 & \dots & l_{n,n-1} & l_{nn}
\end{bmatrix}
\]

\[
U = \begin{bmatrix}
    u_{11} & u_{12} & \dots & u_{1n} \\
    0 & u_{22} & \dots & u_{2n} \\
    & & \ddots & \\
    0 & 0 & \dots & u_{nn}
\end{bmatrix}
\]

The zero entries of $A$ are automatically generated by $LU$. Multiplying
$A = LU$, we also find the following conditions:

1. \[ a_{11} = l_{11}, \quad a_{i,i-1} = l_{i,i-1}, \quad i = 2,3,\dots,n \]
2. \[ a_{ii} = l_{i,i-1} u_{i-1,i} + l_{ii}, \quad i = 2,3,\dots,n \]
3. \[ a_{i,i+1} = l_{ii} u_{i,i+1}, \quad i = 1,2,\dots,n-1 \]

This system is straightforward to solve: (1) gives us $l_{11}$ and the 
off-diagonal entries of $L$. (2) and (3) are used alternately to obtain 
the remaining entries of $L$ and $U$. This solution technique is often referred
to as \textbf{Crout Factorization}.

If we count up the number of operations, we find:

- $(5n - 4)$ multiplications/divisions
- $(3n - 3)$ additions/subtractions

Crout Factorization can be applied to a matrix that is positive definite or one
that is strictly diagonally dominant. See the text for another general case 
where it can be applied.

\end{document}
