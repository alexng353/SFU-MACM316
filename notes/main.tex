\documentclass[12pt]{book}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{enumitem}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{wasysym}
\usepackage{ulem}
\usepackage{xspace}
\usepackage{booktabs}
\usepackage{physics}
\usepackage{titlesec}
\usepackage[most]{tcolorbox}

% greenquote and stuff
\input{lib/quotes}

\titleformat{\chapter}[display]
  {\normalfont\huge\bfseries}
  {\chaptername\ \thechapter}{20pt}{\Huge}
\titlespacing*{\chapter}{0pt}{0pt}{20pt}

\ifPDFTeX % ensure generation of machine readable output
\input{glyphtounicode}
\pdfgentounicode=1
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\fi

\usepackage{csquotes}

\DeclareMathOperator{\dist}{dist}
\DeclareMathOperator{\Nul}{Nul}
\DeclareMathOperator{\Row}{Row}
\DeclareMathOperator{\proj}{proj}

\setlength{\arraycolsep}{12pt}

\newcommand{\Eg}{\textbf{Eg.}\xspace}
\newcommand{\Ex}{\textbf{Ex.}\xspace}
\newcommand{\Ie}{\textbf{I.e.}\xspace}
\newcommand{\bigEps}{\mathcal{E}}
\newcommand{\bproof}{\textit{Proof ($\impliedby$).}\xspace}
\newcommand{\defn}{\textbf{Def.}\xspace}
\newcommand{\eg}{\textbf{e.g.}\xspace}
\newcommand{\ex}{\textbf{ex.}\xspace}
\newcommand{\fproof}{\textit{Proof ($\implies$).}\xspace}
\newcommand{\ie}{\textbf{i.e.}\xspace}
\newcommand{\lemma}{\textit{Lemma}\xspace}
\newcommand{\soln}{\textit{Soln.}\xspace}
\newcommand{\thm}{\textbf{Thm.}\xspace}
\newcommand{\fl}{\operatorname{fl}}

\renewcommand{\arraystretch}{1.25} % Adjust row spacing

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=blue,      
    urlcolor=blue,
}

\newcommand{\ulhref}[2]{\href{#1}{\color{blue}\uline{#2}}}

\begin{document}

\title{Numerical Analysis: The Definitive Edition}
\author{Alexander Ng}
\date{Monday, April 14, 2025\\\small Last Updated: \today}

\maketitle
\include{sections/foreword}
\tableofcontents
\clearpage

\chapter{An Introduction to Numerical Analysis}
\begin{greenquote}
  The first four lectures of this course are an introduction to numerical
  analysis and the main recurring concepts that will be used throughout the
  course.
\end{greenquote}
Many real-world problems stem from numerical analysis, particularly poor 
execution. Rounding errors, insufficient representation problems, and other 
such problems represent the significant impact of computation in the real world.

Check out the following resources for more information:
\begin{enumerate}
  \item \ulhref{https://www-users.cse.umn.edu/~arnold/disasters/}{https://www-users.cse.umn.edu/~arnold/disasters/}
  \item \ulhref{https://web.ma.utexas.edu/users/arbogast/misc/disasters.html}{https://web.ma.utexas.edu/users/arbogast/misc/disasters.html}
\end{enumerate}

\include{sections/chapter1}
% \include{cleaned/Lecture001}
% \include{cleaned/Lecture002}
% \include{cleaned/Lecture003}
% \include{cleaned/Lecture004}
% TODO: put this in it's own section
\section{Review}

Why did we expand around $h_0 = 0$?

\quad Because we want to know what happens with $h_0$, choosing $0$ as our 
expansion point makes sense. The Taylor series approximation is more accurate 
the closer you are to your expansion point.

% As $h \to 0$, the Taylor series approximation converges to the function.

\section{Another Example}

Find the rate of convergence of the following $h\to 0$.

\begin{equation*}
  \lim_{h \to 0} \cos h + \frac{1}{2} h^2 = 1
\end{equation*}

$\alpha = 1$

$\alpha_h = cos h + \frac{1}{2} h^2$

\begin{align*}
  \alpha_h - \alpha &= cos h + \frac{1}{2} h^2 - 1\\
  &= 1-\frac{h^2}{2!}+\frac{h^4}{4!} + O(h^6) + \frac{1}{2}h^2 - 1 \\
  &= \frac{h^4}{4!} + O(h^6) \\
  = O(h^4)
\end{align*}

\chapter{Direct Methods for Solving Linear Systems}
\begin{greenquote}
  Chapter 6 of the textbook.
\end{greenquote}

In MATH 240, we learned methods for solving linear systems of equations where
our $n \times m$ matrix has few rows and few columns. In Numerical Analysis, we
will learn methods for solving linear systems where our matrix has thousands or
millions of rows and columns.

We will first study methods that give an answer in a fixed number of steps, 
subject only to roundoff errors. This method only has error from the accumulation
of numerical representation errors.

\include{cleaned/Lecture005}
\include{cleaned/Lecture006}
\include{cleaned/Lecture007}
\include{cleaned/Lecture008}
\include{cleaned/Lecture009}

\chapter{Iterative Techniques in Matrix Algebra}
\begin{greenquote}
  Chapter 7 of the textbook.
\end{greenquote}

We are interested in solving large linear systems $Ax = b$. We can use certain
properties of $A$, such as $A$ being sparse (\ie having a high percentage of
zeroes), to reduce the amount of computational work required to solve the
system. Unfortunately, the classic Gaussian Elimination does not include any
computational optimizations that can take advantage of most of the special
properties we are interested in. For this reason, we will be considering
\uline{iterative techniques}.

\include{cleaned/Lecture010}
\include{cleaned/Lecture011-a}
\include{cleaned/Lecture011-b}
\include{cleaned/Lecture012}
\include{cleaned/Lecture013} % chapter 2 supposed to start here
\include{cleaned/Lecture014}

\chapter{Solutions of Nonlinear Equations} 
\begin{greenquote}
  Chapter 2 of the text.
\end{greenquote}

We are interested in finding a root $x \in \mathbb{R}$ of an equation of the
form $f(x) = 0$ for a given continuous function $f$. In most cases, it is
impossible to solve this type of problem analytically, so we will consider
iterative methods to approximate the solution.

% we need a section on the intermediate value theorem to preface this chapter
% (probably)

\include{cleaned/Lecture014-b}
\include{cleaned/Lecture015}
\include{cleaned/Lecture016}
\include{cleaned/Lecture017}
\include{cleaned/Lecture018}

\include{cleaned/Lecture019} % chapter 3 supposed to start here

\chapter{Approximation and Interpolation}
\begin{greenquote}
  Chapter 3 of the textbook.
\end{greenquote}

This is the section about splines! You are going to love splines.

\include{cleaned/Lecture020}
\include{cleaned/Lecture021}
\include{cleaned/Lecture022}
\include{cleaned/Lecture023}
\include{cleaned/Lecture024}

\chapter{Numerical Differentiation}
\begin{greenquote}
  Chapter 4 of the textbook. This section is also about Numerical Integration,
  Richardson's Extrapolation, Romberg Integration, Adaptive Quadrature and
  Gaussian Quadrature.
\end{greenquote}

\include{cleaned/Lecture025}
\include{cleaned/Lecture026}
\include{cleaned/Lecture027}
\include{cleaned/Lecture028}
\include{cleaned/Lecture029}
\include{cleaned/Lecture030}
\include{cleaned/Lecture031-b}
\include{cleaned/Lecture031}
\include{cleaned/Lecture032}
\include{cleaned/Lecture033}
\include{cleaned/Lecture034}
\include{cleaned/Lecture035}

\end{document}
